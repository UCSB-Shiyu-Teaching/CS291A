# CS291: Special Topics on Adversarial Machine Learning

This course explores the principles, methodologies, and challenges of **adversarial machine learning**. Students will learn how adversaries can exploit vulnerabilities in machine learning models through adversarial attacks and how to develop defense mechanisms to mitigate these threats.   Key topics include adversarial examples, robustness evaluation, adversarial training, certified defenses, backdoor attacks, model poisoning, and real-world implications in domains such as computer vision and natural language processing.  This **graduate-level, research-oriented** course combines **lectures, paper readings, and student presentations** to facilitate a deep understanding of the field.  By the end of the course, students will be equipped with the knowledge and tools to analyze, defend, and build more secure and resilient machine learning systems.

Instructor: [Prof. Shiyu Chang](https://code-terminator.github.io)

## Course Prerequisites

A strong foundation in machine learning fundamentals, deep learning, and optimization techniques is required. This course assumes familiarity with core ML concepts and model architectures, as these will **not** be covered in class. Prior experience with frameworks such as PyTorch and Hugging Face is recommended.

## Schedule
- **Lectures** will occur Tuesday/Thursday from 9:00-10:45 am Pacific Time at [Phelps 3526](https://classrooms.ucsb.edu/classroom-inventory/phelp-3526).
- **Office hours:** after lectures or by appointment.

Updated lecture slides will be posted here shortly before/after each lecture. 

| Date        | Description                   | Course Materials | Important Events                                       |
|-------------|-------------------------------|------------------|--------------------------------------------------------|
| Tue, 04/01 | Introduction to the course & Optimization | [[Slides](xxxx)]   | |



